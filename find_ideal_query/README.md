# find_ideal_query

Задача: Мы хотим выделить "хорошие" строки из датасетов, то есть те, по которым можно качественно натренировать модель.

Алгоритм:
1. Делаем набор из `INIT_TRAIN_SIZE = 2` случайных примеров
2. Далее добавляем примеры в эту выборку. Будем добавлять `NUM_QUERIES = 100` примеров.
3. Для каждого добавления выделяем `QUERY_SUBSAMPLE_SIZE = 100` возможных примеров и валидационную выборку размера `VALID_SUBSAMPLE_SIZE = 50`.
4. Для каждого возможного примера считаем основную метрику `accuracy` по валидационной выборке. Пример с самым большим `accuracy` идёт в выборку.

NLI датасеты переводятся в датасет для классификации с текстом `premise + SEP_TOKEN + hypothesis`

Используемые NLI датасеты:
* `SNLI`
* `SICK`
* `ANLI_r1`
* `MNLI` (валидационная выборка - `validation_matched`)

Используемые сиды:
* 42
* 34

## Содержимое файлов
* `find_ideal_query.py` - тут содержится сам алгоритм
* `find_ideal_query.ipynb` - тут содержатся запуски скрипта
